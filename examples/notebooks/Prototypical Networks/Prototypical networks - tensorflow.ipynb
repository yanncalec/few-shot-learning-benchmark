{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe0c3e3",
   "metadata": {},
   "source": [
    "# Protypical Networks\n",
    "\n",
    "Keras implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb1c93bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import os\n",
    "import logging\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "Logger = logging.getLogger('protonet')\n",
    "Logger.setLevel(logging.INFO)\n",
    "\n",
    "# import skimage, skimage.io, skimage.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b13350a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-19 23:08:25.887156: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras, nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a8abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a4e430",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcb9e1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: '/home/han/Projects/Few Shot Learning/Notebooks/Prototype_Networks/outputs'\n"
     ]
    }
   ],
   "source": [
    "datadir = os.path.expanduser('~/Database/Machine_Learning')\n",
    "workdir = os.getcwd()\n",
    "\n",
    "outdir = f'{workdir}/outputs'\n",
    "\n",
    "try:\n",
    "    os.makedirs(outdir)\n",
    "except Exception as msg:\n",
    "    print(msg)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2850e9b",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14d729a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## On the original dataset\n",
    "# indir = f'{datadir}/Omniglot/omniglot.original/python/'\n",
    "\n",
    "# foo1 = nd.from_folder(f'{indir}/images_background')\n",
    "# foo2 = nd.from_folder(f'{indir}/images_evaluation')\n",
    "\n",
    "# data_dict = {'images_background': foo1, 'images_evaluation': foo2}\n",
    "# # print(len(data_dict.keys()))\n",
    "\n",
    "# ms = fsl.utils.data.Meta_Sampler(data_dict, 0.75, lvl_split=1, lvl_task=2, n_way=20, k_shot=5)\n",
    "\n",
    "# print(len(ms.trainval_dict.keys()))\n",
    "\n",
    "# print(len(ms.test_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9d077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## On the fused dataset\n",
    "indir = f'{datadir}/Omniglot/omniglot.fused/data/'\n",
    "train_dict, test_dict = fsl.utils.sampler.split_dict_from_folder(indir, 0.75, 0)\n",
    "\n",
    "# data_dict = fsl.utils.nested_dict.from_folder(indir)\n",
    "# train_dict, test_dict = fsl.utils.nested_dict.random_split_level(data_dict, 0.75, 0)\n",
    "\n",
    "# train_sampler = fsl.utils.sampler.Meta_Sampler(train_dict, indir, lvl_task=1, n_way=10, k_shot=5, q_shot=None)\n",
    "# test_sampler = fsl.utils.sampler.Meta_Sampler(test_dict, indir, lvl_task=1, n_way=10, k_shot=5, q_shot=None)\n",
    "# test_sampler = train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea852796",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs_imread = dict(invert=True, dim=(25,25))\n",
    "\n",
    "func = lambda x: fsl.utils.data.imread(x, **kwargs_imread)\n",
    "train_sampler = fsl.utils.sampler.SequentialSampler(train_dict, indir, lvl_task=1, \\\n",
    "                                               n_way=10, k_shot=5, q_shot=None, local=False, func=func, split=True)\n",
    "test_sampler = fsl.utils.sampler.SequentialSampler(test_dict, indir, lvl_task=1, \\\n",
    "                                               n_way=10, k_shot=5, q_shot=None, local=False, func=func, split=True)\n",
    "# train_sampler = fsl.utils.sampler.Meta_Sampler(train_dict, indir, lvl_task=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c9023",
   "metadata": {},
   "source": [
    "## Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fedd3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = fsl.models.tf.ProtoNet((*kwargs_imread['dim'],1))\n",
    "model = fsl.models.tf.ProtoNet.get_model((*kwargs_imread['dim'],1), train_sampler.n_way, train_sampler.k_shot)\n",
    "# model = fsl.models.tf.get_model(kwargs_imread['dim'])\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=1)],\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=5e-4))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbc55ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 14s 110ms/step - loss: 4.0277 - sparse_top_k_categorical_accuracy: 0.0250 - val_loss: 2.4908 - val_sparse_top_k_categorical_accuracy: 0.0429\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 12s 98ms/step - loss: 2.4407 - sparse_top_k_categorical_accuracy: 0.0466 - val_loss: 2.4076 - val_sparse_top_k_categorical_accuracy: 0.0476\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 2.3811 - sparse_top_k_categorical_accuracy: 0.0534 - val_loss: 2.3746 - val_sparse_top_k_categorical_accuracy: 0.0509\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 13s 107ms/step - loss: 2.3541 - sparse_top_k_categorical_accuracy: 0.0628 - val_loss: 2.3567 - val_sparse_top_k_categorical_accuracy: 0.0558\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 2.3404 - sparse_top_k_categorical_accuracy: 0.0664 - val_loss: 2.3414 - val_sparse_top_k_categorical_accuracy: 0.0626\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 2.3308 - sparse_top_k_categorical_accuracy: 0.0705 - val_loss: 2.3450 - val_sparse_top_k_categorical_accuracy: 0.0603\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 2.3239 - sparse_top_k_categorical_accuracy: 0.0776 - val_loss: 2.3320 - val_sparse_top_k_categorical_accuracy: 0.0676\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 14s 116ms/step - loss: 2.3193 - sparse_top_k_categorical_accuracy: 0.0841 - val_loss: 2.3301 - val_sparse_top_k_categorical_accuracy: 0.0641\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 15s 123ms/step - loss: 2.3162 - sparse_top_k_categorical_accuracy: 0.0893 - val_loss: 2.3288 - val_sparse_top_k_categorical_accuracy: 0.0629\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 14s 114ms/step - loss: 2.3129 - sparse_top_k_categorical_accuracy: 0.0904 - val_loss: 2.3257 - val_sparse_top_k_categorical_accuracy: 0.0641\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 14s 115ms/step - loss: 2.3103 - sparse_top_k_categorical_accuracy: 0.0989 - val_loss: 2.3260 - val_sparse_top_k_categorical_accuracy: 0.0698\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 13s 112ms/step - loss: 2.3097 - sparse_top_k_categorical_accuracy: 0.0969 - val_loss: 2.3235 - val_sparse_top_k_categorical_accuracy: 0.0719\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 2.3082 - sparse_top_k_categorical_accuracy: 0.0987 - val_loss: 2.3238 - val_sparse_top_k_categorical_accuracy: 0.0673\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 13s 109ms/step - loss: 2.3064 - sparse_top_k_categorical_accuracy: 0.1031 - val_loss: 2.3203 - val_sparse_top_k_categorical_accuracy: 0.0756\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 2.3057 - sparse_top_k_categorical_accuracy: 0.1043 - val_loss: 2.3205 - val_sparse_top_k_categorical_accuracy: 0.0813\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 2.3031 - sparse_top_k_categorical_accuracy: 0.1096 - val_loss: 2.3208 - val_sparse_top_k_categorical_accuracy: 0.0763\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 13s 110ms/step - loss: 2.3025 - sparse_top_k_categorical_accuracy: 0.1109 - val_loss: 2.3219 - val_sparse_top_k_categorical_accuracy: 0.0750\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 13s 111ms/step - loss: 2.3018 - sparse_top_k_categorical_accuracy: 0.1124 - val_loss: 2.3222 - val_sparse_top_k_categorical_accuracy: 0.0766\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 13s 108ms/step - loss: 2.3007 - sparse_top_k_categorical_accuracy: 0.1172 - val_loss: 2.3244 - val_sparse_top_k_categorical_accuracy: 0.0730\n",
      "Epoch 20/100\n",
      " 79/120 [==================>...........] - ETA: 4s - loss: 2.2999 - sparse_top_k_categorical_accuracy: 0.1176"
     ]
    }
   ],
   "source": [
    "res = model.fit(train_sampler, validation_data=test_sampler, epochs=100, use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace5f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5c6d5ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_996272/2554063989.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{outdir}/multi_input_and_output_model.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "\n",
    "keras.utils.plot_model(model, f\"{outdir}/model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = tf.convert_to_tensor(np.random.randn(10,5,100,100,1))\n",
    "Q = tf.convert_to_tensor(np.random.randn(10,15,100,100,1))\n",
    "\n",
    "Y = model([Q, S])\n",
    "\n",
    "Yp = tf.nn.softmax(Y, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036ff72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 10\n",
    "q_shot = 15\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "Yt = np.tile(np.arange(n_way), (q_shot,1)).T.flatten()\n",
    "\n",
    "scce(Yt, Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f9a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_way = 10\n",
    "q_shot = 15\n",
    "\n",
    "scce = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "Yt = np.tile(np.arange(n_way), (q_shot,1)).T.flatten()\n",
    "\n",
    "scce(Yt, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e1f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "Yt = np.tile(np.arange(n_way)[:,None], (1,q_shot))  # target labels\n",
    "\n",
    "Yt = tf.reshape(tf.one_hot(Yt, depth=n_way, axis=-1), (-1,n_way))\n",
    "\n",
    "# cce = np.mean(keras.losses.categorical_crossentropy(Yt, Yp, from_logits=False))\n",
    "\n",
    "cce = tf.keras.losses.CategoricalCrossentropy()\n",
    "cce(Yt, Yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc69f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = tf.keras.metrics.SparseTopKCategoricalAccuracy(k=1)\n",
    "acc.update_state(Yt, Yp)\n",
    "acc.result().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4047e5",
   "metadata": {},
   "source": [
    "## EOF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev38_pip)",
   "language": "python",
   "name": "dev38_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
